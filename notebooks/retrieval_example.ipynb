{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6389d9b5",
   "metadata": {},
   "source": [
    "# Retrieval Layer — Example Query Notebook\n",
    "\n",
    "This notebook demonstrates the **agentic-rag-kubeflow** retrieval layer\n",
    "using a lightweight in-memory vector store so that it runs entirely\n",
    "self-contained (no Chroma server required).\n",
    "\n",
    "**What you'll see:**\n",
    "1. Vector DB abstraction (`VectorStoreBase` / `FakeVectorStore`)\n",
    "2. Top-k semantic search\n",
    "3. Metadata-aware filtering with `MetadataFilter`\n",
    "4. Citation tracking with `Citation` and `RetrievalResult`\n",
    "5. Score-threshold filtering\n",
    "6. Formatted results table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd3cf5",
   "metadata": {},
   "source": [
    "## 1 — Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282bfb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All retrieval imports successful\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys, pathlib\n",
    "\n",
    "# Ensure the project src/ is on the path so we can import agentic_rag\n",
    "_project_root = pathlib.Path.cwd().parent if pathlib.Path.cwd().name == \"notebooks\" else pathlib.Path.cwd()\n",
    "if str(_project_root / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(_project_root / \"src\"))\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from agentic_rag.retrieval.base import VectorStoreBase\n",
    "from agentic_rag.retrieval.models import Citation, MetadataFilter, RetrievalResult\n",
    "from agentic_rag.retrieval.retriever import SemanticRetriever\n",
    "\n",
    "print(\"✓ All retrieval imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9286e",
   "metadata": {},
   "source": [
    "## 2 — In-Memory Fake Vector Store\n",
    "\n",
    "We create a simple in-memory backend that implements `VectorStoreBase`.\n",
    "This lets us demo the full retrieval pipeline without a running Chroma server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bab0c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FakeVectorStore defined\n"
     ]
    }
   ],
   "source": [
    "class FakeVectorStore(VectorStoreBase):\n",
    "    \"\"\"Deterministic in-memory store seeded with sample documents.\"\"\"\n",
    "\n",
    "    def __init__(self, docs: list[dict[str, Any]]) -> None:\n",
    "        super().__init__(\"demo-collection\")\n",
    "        self._docs = docs\n",
    "\n",
    "    def similarity_search(\n",
    "        self,\n",
    "        query_embedding: list[float],\n",
    "        *,\n",
    "        k: int = 5,\n",
    "        filters: list[MetadataFilter] | None = None,\n",
    "    ) -> list[dict[str, Any]]:\n",
    "        return self._apply_filters(filters)[:k]\n",
    "\n",
    "    def similarity_search_by_text(\n",
    "        self,\n",
    "        query: str,\n",
    "        *,\n",
    "        k: int = 5,\n",
    "        filters: list[MetadataFilter] | None = None,\n",
    "    ) -> list[dict[str, Any]]:\n",
    "        return self._apply_filters(filters)[:k]\n",
    "\n",
    "    def health_check(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    # ---- helpers ----\n",
    "    def _apply_filters(self, filters: list[MetadataFilter] | None) -> list[dict[str, Any]]:\n",
    "        if not filters:\n",
    "            return list(self._docs)\n",
    "        results = []\n",
    "        for doc in self._docs:\n",
    "            meta = doc.get(\"metadata\", {})\n",
    "            if all(self._match(f, meta) for f in filters):\n",
    "                results.append(doc)\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def _match(f: MetadataFilter, meta: dict[str, Any]) -> bool:\n",
    "        val = meta.get(f.field)\n",
    "        if f.operator == \"eq\":\n",
    "            return val == f.value\n",
    "        if f.operator == \"ne\":\n",
    "            return val != f.value\n",
    "        if f.operator == \"in\":\n",
    "            return val in f.value\n",
    "        if f.operator == \"gt\":\n",
    "            return val is not None and val > f.value\n",
    "        if f.operator == \"gte\":\n",
    "            return val is not None and val >= f.value\n",
    "        if f.operator == \"lt\":\n",
    "            return val is not None and val < f.value\n",
    "        if f.operator == \"lte\":\n",
    "            return val is not None and val <= f.value\n",
    "        return True\n",
    "\n",
    "print(\"✓ FakeVectorStore defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f7009",
   "metadata": {},
   "source": [
    "## 3 — Seed Sample Documents\n",
    "\n",
    "We populate the store with a small corpus of chunks with rich metadata\n",
    "so that filtering and citation tracing are clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ca39be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Seeded store with 6 chunks\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_DOCS: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"id\": \"chunk-001\",\n",
    "        \"content\": (\n",
    "            \"Kubeflow Pipelines is a platform for building and deploying portable, \"\n",
    "            \"scalable ML workflows based on Docker containers.\"\n",
    "        ),\n",
    "        \"score\": 0.95,\n",
    "        \"metadata\": {\n",
    "            \"source\": \"kubeflow_pipelines_guide.md\",\n",
    "            \"chunk_index\": 0,\n",
    "            \"page\": 1,\n",
    "            \"category\": \"orchestration\",\n",
    "            \"date\": \"2025-06-15\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"chunk-002\",\n",
    "        \"content\": (\n",
    "            \"KServe provides a Kubernetes CRD for serving ML models with \"\n",
    "            \"autoscaling, canary rollouts, and pre-/post-processing.\"\n",
    "        ),\n",
    "        \"score\": 0.91,\n",
    "        \"metadata\": {\n",
    "            \"source\": \"kserve_docs.md\",\n",
    "            \"chunk_index\": 3,\n",
    "            \"page\": 12,\n",
    "            \"category\": \"serving\",\n",
    "            \"date\": \"2025-08-01\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"chunk-003\",\n",
    "        \"content\": (\n",
    "            \"LangGraph enables building stateful, multi-actor applications with \"\n",
    "            \"LLMs by modelling workflows as graphs.\"\n",
    "        ),\n",
    "        \"score\": 0.88,\n",
    "        \"metadata\": {\n",
    "            \"source\": \"langgraph_overview.md\",\n",
    "            \"chunk_index\": 1,\n",
    "            \"category\": \"agents\",\n",
    "            \"date\": \"2025-09-20\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"chunk-004\",\n",
    "        \"content\": (\n",
    "            \"ChromaDB is an open-source embedding database designed for AI \"\n",
    "            \"applications with first-class LangChain integration.\"\n",
    "        ),\n",
    "        \"score\": 0.82,\n",
    "        \"metadata\": {\n",
    "            \"source\": \"chroma_overview.md\",\n",
    "            \"chunk_index\": 0,\n",
    "            \"category\": \"vector-db\",\n",
    "            \"date\": \"2025-04-10\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"chunk-005\",\n",
    "        \"content\": (\n",
    "            \"Retrieval-Augmented Generation (RAG) combines a retriever over a \"\n",
    "            \"knowledge base with a generative LLM to reduce hallucinations.\"\n",
    "        ),\n",
    "        \"score\": 0.78,\n",
    "        \"metadata\": {\n",
    "            \"source\": \"rag_survey_arxiv.md\",\n",
    "            \"chunk_index\": 2,\n",
    "            \"page\": 5,\n",
    "            \"category\": \"research\",\n",
    "            \"date\": \"2024-11-30\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"chunk-006\",\n",
    "        \"content\": (\n",
    "            \"Sentence-Transformers maps sentences to a 384-dimensional dense \"\n",
    "            \"vector space suitable for semantic search and clustering.\"\n",
    "        ),\n",
    "        \"score\": 0.40,\n",
    "        \"metadata\": {\n",
    "            \"source\": \"sentence_transformers_docs.md\",\n",
    "            \"chunk_index\": 0,\n",
    "            \"category\": \"embeddings\",\n",
    "            \"date\": \"2025-01-05\",\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "store = FakeVectorStore(SAMPLE_DOCS)\n",
    "print(f\"✓ Seeded store with {len(SAMPLE_DOCS)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6491170",
   "metadata": {},
   "source": [
    "## 4 — Basic Top-k Semantic Search\n",
    "\n",
    "Run a simple search over all documents, returning the top 3 results\n",
    "with full citation provenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd93f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#    Score  Source                              Chunk  Content\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     0.95  kubeflow_pipelines_guide.md             -  Kubeflow Pipelines is a platform for building and deplo…\n",
      "2     0.91  kserve_docs.md                          3  KServe provides a Kubernetes CRD for serving ML models …\n",
      "3     0.88  langgraph_overview.md                   1  LangGraph enables building stateful, multi-actor applic…\n"
     ]
    }
   ],
   "source": [
    "retriever = SemanticRetriever(store=store, default_k=3)\n",
    "\n",
    "results = retriever.search(\"How does Kubeflow orchestrate ML workflows?\")\n",
    "\n",
    "print(f\"{'#':<3} {'Score':>6}  {'Source':<35} {'Chunk':>5}  Content\")\n",
    "print(\"-\" * 100)\n",
    "for i, r in enumerate(results, 1):\n",
    "    c = r.citation\n",
    "    print(f\"{i:<3} {c.score:>6.2f}  {c.source:<35} {c.chunk_index or '-':>5}  {r.content[:55]}…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985a6500",
   "metadata": {},
   "source": [
    "## 5 — Metadata Filtering\n",
    "\n",
    "Filter results to only documents in the **\"orchestration\"** or **\"serving\"** categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e7a274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with category ∈ {orchestration, serving}  (2 hits)\n",
      "\n",
      "  [kubeflow_pipelines_guide.md§0]  score=0.95  category=orchestration\n",
      "    → Kubeflow Pipelines is a platform for building and deploying portable, scalable M…\n",
      "\n",
      "  [kserve_docs.md§3]  score=0.91  category=serving\n",
      "    → KServe provides a Kubernetes CRD for serving ML models with autoscaling, canary …\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter: category must be one of \"orchestration\" or \"serving\"\n",
    "category_filter = MetadataFilter.one_of(\"category\", [\"orchestration\", \"serving\"])\n",
    "\n",
    "filtered = retriever.search(\n",
    "    \"ML deployment\",\n",
    "    k=5,\n",
    "    filters=[category_filter],\n",
    ")\n",
    "\n",
    "print(f\"Results with category ∈ {{orchestration, serving}}  ({len(filtered)} hits)\\n\")\n",
    "for r in filtered:\n",
    "    c = r.citation\n",
    "    print(f\"  {c.short_ref()}  score={c.score:.2f}  category={c.metadata.get('category')}\")\n",
    "    print(f\"    → {r.content[:80]}…\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e10110",
   "metadata": {},
   "source": [
    "## 6 — Score Threshold Filtering\n",
    "\n",
    "Create a stricter retriever that drops any result with similarity < 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "733a9ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All chunks: 6 | After threshold ≥ 0.5: 5\n",
      "\n",
      "  0.95  kubeflow_pipelines_guide.md\n",
      "  0.91  kserve_docs.md\n",
      "  0.88  langgraph_overview.md\n",
      "  0.82  chroma_overview.md\n",
      "  0.78  rag_survey_arxiv.md\n"
     ]
    }
   ],
   "source": [
    "strict_retriever = SemanticRetriever(store=store, default_k=10, score_threshold=0.5)\n",
    "\n",
    "strict_results = strict_retriever.search(\"embeddings and vector search\")\n",
    "\n",
    "print(f\"All chunks: {len(SAMPLE_DOCS)} | After threshold ≥ 0.5: {len(strict_results)}\\n\")\n",
    "for r in strict_results:\n",
    "    print(f\"  {r.citation.score:.2f}  {r.citation.source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8716a77",
   "metadata": {},
   "source": [
    "## 7 — Citation Deep-Dive\n",
    "\n",
    "Inspect the full `Citation` object to show how every result traces\n",
    "back to its source document, chunk position, and page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c316fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── Result 1 ──────────────────────────────────────────────\n",
      "  Citation ID  : 712063ff1ba9\n",
      "  Document ID  : chunk-001\n",
      "  Source       : kubeflow_pipelines_guide.md\n",
      "  Chunk index  : 0\n",
      "  Page         : 1\n",
      "  Score        : 0.9500\n",
      "  Retrieved at : 2026-02-12T05:52:16.886602+00:00\n",
      "  Short ref    : [kubeflow_pipelines_guide.md§0]\n",
      "  Metadata     : {\n",
      "  \"source\": \"kubeflow_pipelines_guide.md\",\n",
      "  \"chunk_index\": 0,\n",
      "  \"page\": 1,\n",
      "  \"category\": \"orchestration\",\n",
      "  \"date\": \"2025-06-15\"\n",
      "}\n",
      "  Content      : Kubeflow Pipelines is a platform for building and deploying portable, scalable ML workflow…\n",
      "\n",
      "── Result 2 ──────────────────────────────────────────────\n",
      "  Citation ID  : 2230fe02bbbc\n",
      "  Document ID  : chunk-002\n",
      "  Source       : kserve_docs.md\n",
      "  Chunk index  : 3\n",
      "  Page         : 12\n",
      "  Score        : 0.9100\n",
      "  Retrieved at : 2026-02-12T05:52:16.886701+00:00\n",
      "  Short ref    : [kserve_docs.md§3]\n",
      "  Metadata     : {\n",
      "  \"source\": \"kserve_docs.md\",\n",
      "  \"chunk_index\": 3,\n",
      "  \"page\": 12,\n",
      "  \"category\": \"serving\",\n",
      "  \"date\": \"2025-08-01\"\n",
      "}\n",
      "  Content      : KServe provides a Kubernetes CRD for serving ML models with autoscaling, canary rollouts, …\n",
      "\n",
      "── Result 3 ──────────────────────────────────────────────\n",
      "  Citation ID  : 11ad2ab5e350\n",
      "  Document ID  : chunk-003\n",
      "  Source       : langgraph_overview.md\n",
      "  Chunk index  : 1\n",
      "  Page         : N/A\n",
      "  Score        : 0.8800\n",
      "  Retrieved at : 2026-02-12T05:52:16.886869+00:00\n",
      "  Short ref    : [langgraph_overview.md§1]\n",
      "  Metadata     : {\n",
      "  \"source\": \"langgraph_overview.md\",\n",
      "  \"chunk_index\": 1,\n",
      "  \"category\": \"agents\",\n",
      "  \"date\": \"2025-09-20\"\n",
      "}\n",
      "  Content      : LangGraph enables building stateful, multi-actor applications with LLMs by modelling workf…\n",
      "\n",
      "── Result 4 ──────────────────────────────────────────────\n",
      "  Citation ID  : 2d328da8f794\n",
      "  Document ID  : chunk-004\n",
      "  Source       : chroma_overview.md\n",
      "  Chunk index  : 0\n",
      "  Page         : N/A\n",
      "  Score        : 0.8200\n",
      "  Retrieved at : 2026-02-12T05:52:16.886914+00:00\n",
      "  Short ref    : [chroma_overview.md§0]\n",
      "  Metadata     : {\n",
      "  \"source\": \"chroma_overview.md\",\n",
      "  \"chunk_index\": 0,\n",
      "  \"category\": \"vector-db\",\n",
      "  \"date\": \"2025-04-10\"\n",
      "}\n",
      "  Content      : ChromaDB is an open-source embedding database designed for AI applications with first-clas…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "full_results = retriever.search(\"Tell me about RAG and vector databases\", k=4)\n",
    "\n",
    "for i, r in enumerate(full_results, 1):\n",
    "    c = r.citation\n",
    "    print(f\"── Result {i} ──────────────────────────────────────────────\")\n",
    "    print(f\"  Citation ID  : {c.citation_id}\")\n",
    "    print(f\"  Document ID  : {c.document_id}\")\n",
    "    print(f\"  Source       : {c.source}\")\n",
    "    print(f\"  Chunk index  : {c.chunk_index}\")\n",
    "    print(f\"  Page         : {c.page or 'N/A'}\")\n",
    "    print(f\"  Score        : {c.score:.4f}\")\n",
    "    print(f\"  Retrieved at : {c.retrieved_at.isoformat()}\")\n",
    "    print(f\"  Short ref    : {c.short_ref()}\")\n",
    "    print(f\"  Metadata     : {json.dumps(c.metadata, indent=2)}\")\n",
    "    print(f\"  Content      : {r.content[:90]}…\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccead46",
   "metadata": {},
   "source": [
    "## 8 — Combined: Metadata Filter + Score Threshold\n",
    "\n",
    "Filter for documents dated after 2025-05-01, with strict score threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175b1204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters: date > 2025-05-01 + score ≥ 0.5  →  3 results\n",
      "\n",
      "Source                              Date         Category         Score\n",
      "---------------------------------------------------------------------------\n",
      "kubeflow_pipelines_guide.md         2025-06-15   orchestration     0.95\n",
      "kserve_docs.md                      2025-08-01   serving           0.91\n",
      "langgraph_overview.md               2025-09-20   agents            0.88\n"
     ]
    }
   ],
   "source": [
    "# Combine: date > 2025-05-01 AND score ≥ 0.5\n",
    "date_filter = MetadataFilter(field=\"date\", operator=\"gt\", value=\"2025-05-01\")\n",
    "\n",
    "combo_retriever = SemanticRetriever(store=store, default_k=10, score_threshold=0.5)\n",
    "combo_results = combo_retriever.search(\"ML infrastructure\", filters=[date_filter])\n",
    "\n",
    "print(f\"Filters: date > 2025-05-01 + score ≥ 0.5  →  {len(combo_results)} results\\n\")\n",
    "print(f\"{'Source':<35} {'Date':<12} {'Category':<15} {'Score':>6}\")\n",
    "print(\"-\" * 75)\n",
    "for r in combo_results:\n",
    "    c = r.citation\n",
    "    print(\n",
    "        f\"{c.source:<35} {c.metadata.get('date', 'N/A'):<12} \"\n",
    "        f\"{c.metadata.get('category', 'N/A'):<15} {c.score:>6.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f0fa3",
   "metadata": {},
   "source": [
    "## 9 — Serialization (API / Agent Handoff)\n",
    "\n",
    "`RetrievalResult` and `Citation` are Pydantic models, so they serialize\n",
    "cleanly for JSON APIs or agent tool responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c7598ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Kubeflow Pipelines is a platform for building and deploying portable, scalable ML workflows based on Docker containers.\",\n",
      "  \"citation\": {\n",
      "    \"citation_id\": \"36ba2cc70969\",\n",
      "    \"document_id\": \"chunk-001\",\n",
      "    \"source\": \"kubeflow_pipelines_guide.md\",\n",
      "    \"chunk_index\": 0,\n",
      "    \"page\": 1,\n",
      "    \"score\": 0.95,\n",
      "    \"metadata\": {\n",
      "      \"source\": \"kubeflow_pipelines_guide.md\",\n",
      "      \"chunk_index\": 0,\n",
      "      \"page\": 1,\n",
      "      \"category\": \"orchestration\",\n",
      "      \"date\": \"2025-06-15\"\n",
      "    },\n",
      "    \"retrieved_at\": \"2026-02-12T05:51:53.556635Z\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Serialize the first result to JSON (e.g. for an API response)\n",
    "first = results[0]\n",
    "payload = first.model_dump_json(indent=2)\n",
    "print(payload)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
